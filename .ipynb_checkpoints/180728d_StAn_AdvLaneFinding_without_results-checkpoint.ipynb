{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Advanced Lane Finding\n",
    "\n",
    "This project has been prepared by Andre Strobel.\n",
    "\n",
    "The goal of this project is to find a vehicle's lane in a video stream. The video stream has been recorded with a forward facing camera that is mounted to the vehicle. The detected lane is then used to estimate the lateral curvature of the road.\n",
    "\n",
    "Everything has been programmed in Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. Camera setup\n",
    "    1. Distortion correction based on several test images\n",
    "    1. Transformation to birds-eye view\n",
    "    1. Pixel to real world transformation\n",
    "1. Processing individual frames from a video stream to detect the lane and lateral curvature\n",
    "    1. Generate binary images to detect lane lines using different methods and parameters\n",
    "    1. Identify left and right lane lines with and without prior knowledge about their shape and positions\n",
    "    1. Manage left and right lane line detection quality and determine what to use\n",
    "1. Output a video stream that contains information about the lane ahead\n",
    "    1. Mark up the lane ahead\n",
    "    1. Mark up left and right lane lines with different color\n",
    "    1. Print the lateral curvature value and lateral offset from the center of the lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic definitions\n",
    "\n",
    "The following section defines a framework for the actual code of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary libraries\n",
    "\n",
    "This project uses the file globbing (`glob`), miscellaneous operating system interfaces (`os`), copying (`copy`), Open-CV (`cv2`) and NumPy (`numpy`) packages as well as several subpackages from the `matplotlib` package (`pyplot`, `image`). In order to process and display videos, the objects `VideoFileClip` and `ImageSequenceClip` are imported from the package `moviepy.editor` and the object `HTML` is imported from `IPython.display`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define exception handling\n",
    "\n",
    "A generic exception class `Error` is defined to handle potential issues during the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def __str__(self):\n",
    "        return repr(self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classes\n",
    "\n",
    "The class `Line` is defined to store previous findings of the left, right and all lane lines. The class `Lane` is defined to store previous findings of the lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        # starting peak positions\n",
    "        self.startpeak = None\n",
    "        \n",
    "class Lane():\n",
    "    def __init__(self):\n",
    "        # last found lane_mask\n",
    "        self.lane_mask = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "The `weighted_image` function blends two images into one image. The `blendinto_image` function adds a second image to the first image. The `addto_image` function adds all non black pixels of an image to another image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_image(image1, weight, image2):\n",
    "# ...\n",
    "# This function blends two images using the weight [0, 1] for the first image\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# image1 : first image\n",
    "# weight : weight used for first image - must be between 0 and 1\n",
    "# image2 : second image\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# blended : blended image\n",
    "    \n",
    "    # blend images\n",
    "    blended = cv2.addWeighted(image1, weight, image2, (1 - weight), 0)\n",
    "    \n",
    "    return blended\n",
    "\n",
    "def blendinto_image(image1, image2, weight):\n",
    "# ...\n",
    "# This function adds a second image to the first image using the weight [0, 1]\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# image1 : first image\n",
    "# image2 : second image\n",
    "# weight : weight used to add the second image to the first image - must be between 0 and 1\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# blended : blended image\n",
    "    \n",
    "    # blend images\n",
    "    blended = cv2.addWeighted(image1, 1, image2, weight, 0)\n",
    "    \n",
    "    return blended\n",
    "\n",
    "def addto_image(image, maskimage):\n",
    "# ...\n",
    "# This function adds all non-zero (non black) pixels of a second image to the first image\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# image     : first image\n",
    "# maskimage : second image\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# ret      : boolean for \"successful operation\"\n",
    "# combined : combined image\n",
    "    \n",
    "    # initialize output\n",
    "    ret = True\n",
    "    \n",
    "    # copy first image\n",
    "    combined = np.copy(image)\n",
    "    \n",
    "    # determine image size\n",
    "    targetysize = combined.shape[0]\n",
    "    targetxsize = combined.shape[1]\n",
    "    targetcsize = combined.shape[2]\n",
    "    \n",
    "    # determine mask size\n",
    "    ysize = maskimage.shape[0]\n",
    "    xsize = maskimage.shape[1]\n",
    "    csize = maskimage.shape[2]\n",
    "    \n",
    "    # combined image cannot be smaller than mask image\n",
    "    if not ((targetysize < ysize) or (targetxsize < xsize) or (targetcsize < csize)):\n",
    "        \n",
    "        # replace all non-zero pixels\n",
    "        for idxy, y in enumerate(range(ysize)):\n",
    "            for idxx, x in enumerate(range(xsize)):\n",
    "                if not ((maskimage[y, x, 0] == 0) and (maskimage[y, x, 1] == 0) and (maskimage[y, x, 2] == 0)):\n",
    "                    combined[y, x, 0] = maskimage[y, x, 0]\n",
    "                    combined[y, x, 1] = maskimage[y, x, 1]\n",
    "                    combined[y, x, 2] = maskimage[y, x, 2]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # return error flag\n",
    "        ret = False\n",
    "    \n",
    "    return ret, combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera setup process\n",
    "\n",
    "The camera setup defines a sequence of functions to correct and transform camaera images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera calibration\n",
    "\n",
    "The `camera_calibration` function is based on the Open-CV tutorial (http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html) and Udacity tutorial (https://github.com/udacity/CarND-Camera-Calibration/blob/master/camera_calibration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_calibration(calsubfolder = 'camera_cal', calimagemask = '*.jpg', numcalpicpointsx = 9, numcalpicpointsy = 6, bdisplay = False):\n",
    "# ...\n",
    "# This function calibrates a camera with numcalpicpointsx times numcalpicpointsy chessboard pictures\n",
    "# in the subfolder calsubfolder based on images of the mask calimagemask\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# calsubfolder     : folder with calibration images\n",
    "# calimagemask     : name mask for calibration images\n",
    "# numcalpicpointsx : number of chessboard elements in horizontal direction\n",
    "# numcalpicpointsy : number of chessboard elements in vertical direction\n",
    "# bdisplay         : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# ret   : boolean for \"succesful execution\"\n",
    "# mtx   : camera matrix\n",
    "# dist  : distortion coefficients\n",
    "# rvecs : rotation vectors\n",
    "# tvecs : translation vectors\n",
    "  \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('camera_calibration')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "    objp = np.zeros(((numcalpicpointsy * numcalpicpointsx), 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:numcalpicpointsx, 0:numcalpicpointsy].T.reshape(-1, 2)\n",
    "    \n",
    "    # arrays to store object points and image points from all the images\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane\n",
    "\n",
    "    # get a list of calibration images\n",
    "    fileimages = glob.glob(os.path.join('.', calsubfolder, calimagemask))\n",
    "\n",
    "    # initialize variables\n",
    "    images = []\n",
    "    grays =[]\n",
    "    corners =[]\n",
    "    \n",
    "    # loop through all images\n",
    "    for idx, fileimage in enumerate(fileimages):\n",
    "        \n",
    "        # read image as gray scale\n",
    "        images.append(mpimg.imread(fileimage))\n",
    "        grays.append(cv2.cvtColor(images[idx], cv2.COLOR_BGR2GRAY))\n",
    "        \n",
    "        # find the chess board corners\n",
    "        ret, newcorners = cv2.findChessboardCorners(grays[idx], (numcalpicpointsx, numcalpicpointsy), None)\n",
    "        corners.append(newcorners)\n",
    "\n",
    "        # if found, add object points, image points\n",
    "        if ret == True:\n",
    "            \n",
    "            # add found corners to calibration lists\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners[idx])\n",
    "            \n",
    "    # calibrate camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, grays[idx].shape[::-1], None, None)\n",
    "\n",
    "    # draw and display marked and undistorted images\n",
    "    if bdisplay:\n",
    "    \n",
    "        # loop through all images\n",
    "        for idx, fileimage in enumerate(fileimages):\n",
    "            \n",
    "            # mark up corners in image\n",
    "            print('Processing image:', fileimage)\n",
    "            markedimage = cv2.drawChessboardCorners(images[idx], (numcalpicpointsx, numcalpicpointsy), corners[idx], True)\n",
    "            undistortedimage = cv2.undistort(markedimage, mtx, dist, None, mtx)\n",
    "            figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "            figure.tight_layout()\n",
    "            ax1.imshow(markedimage)\n",
    "            ax1.set_title('Marked calibration image', fontsize=30)\n",
    "            ax2.imshow(undistortedimage)\n",
    "            ax2.set_title('Undistorted marked calibration image', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "            plt.show()\n",
    "    \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    return (ret, mtx, dist, rvecs, tvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera to birdseye view\n",
    "\n",
    "The `camera2birdseyeview` function is based on the material from the Udacity SDC nanodegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera2birdseyeview(mtx, dist, testsubfolder = 'test_images', testimage = 'straight_lines1.jpg', testimagemask = '*.jpg', offsetxpercent = 30, offsetypercent = 0, bdisplay = False):\n",
    "# ...\n",
    "# This function calculates the transformations from camera to birdseye view and vice versa\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# mtx            : camera matrix\n",
    "# dist           : distortion coefficients\n",
    "# testsubfolder  : folder with test image\n",
    "# testimage      : test image name\n",
    "# testimagemask  : name mask for test images\n",
    "# offsetxpercent : x direction offset around transformation box in percent\n",
    "# offsetypercent : y direction offset around transformation box in percent\n",
    "# bdisplay       : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# ret : boolean for \"succesful execution\"\n",
    "# M   : transformation matrix from camera to birdseye view\n",
    "# N   : transformation matrix from birdseye view to camera\n",
    "\n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('camera2birdseyeview')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # constants\n",
    "    drawweight = 0.8 # weight for adding area used for transformation\n",
    "    linewidth = 10 # width of dimensions in image\n",
    "    \n",
    "    # initialize output\n",
    "    ret = True\n",
    "    \n",
    "    # read and undistort test image based on which transformation will be determined\n",
    "    fileimage = os.path.join('.', testsubfolder, testimage)\n",
    "    image = mpimg.imread(fileimage)\n",
    "    undistortedimage = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    xsize = undistortedimage.shape[1]\n",
    "    ysize = undistortedimage.shape[0]\n",
    "    \n",
    "    # manually define source points => look for algorithm in the future\n",
    "    srcymin = 450\n",
    "    srcymax = 720\n",
    "    srcpoint_bottom_left_x = 200\n",
    "    srcpoint_bottom_left_y = srcymax\n",
    "    srcpoint_top_left_x = 594\n",
    "    srcpoint_top_left_y = srcymin\n",
    "    srcpoint_top_right_x = 685\n",
    "    srcpoint_top_right_y = srcymin\n",
    "    srcpoint_bottom_right_x = 1100\n",
    "    srcpoint_bottom_right_y = srcymax\n",
    "    src = np.float32([[srcpoint_bottom_left_x, srcpoint_bottom_left_y],\n",
    "                      [srcpoint_top_left_x, srcpoint_top_left_y], \n",
    "                      [srcpoint_top_right_x, srcpoint_top_right_y], \n",
    "                      [srcpoint_bottom_right_x, srcpoint_bottom_right_y]])\n",
    "    \n",
    "    # define destination points\n",
    "    dstxmin = 0 + (xsize * offsetxpercent / 100)\n",
    "    dstxmax = xsize - 1 - (xsize * offsetxpercent / 100)\n",
    "    dstymin = 0 + (ysize * offsetypercent / 100)\n",
    "    dstymax = ysize - 1 - (ysize * offsetypercent / 100)\n",
    "    dst = np.float32([[dstxmin, dstymax], [dstxmin, dstymin], [dstxmax, dstymin], [dstxmax, dstymax]])\n",
    "    \n",
    "    # calculate transformation matrices\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    N = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # draw and display test image and birdseye view image\n",
    "    if bdisplay:\n",
    "        \n",
    "        # print name of used test image\n",
    "        print('Processing image:', fileimage)\n",
    "        \n",
    "        # draw area used for transformation into original image\n",
    "        points = np.int32(src.reshape((-1,1,2)))\n",
    "        srcareaimage = np.zeros_like(undistortedimage)\n",
    "        cv2.polylines(srcareaimage, [points], True, (0, 255, 0), thickness = linewidth)\n",
    "        blended = blendinto_image(undistortedimage, srcareaimage, drawweight)\n",
    "        \n",
    "        # make perspective transformation of original image with area used for transformation\n",
    "        xsize = blended.shape[1]\n",
    "        ysize = blended.shape[0]        \n",
    "        warpedimage = cv2.warpPerspective(blended, M, (xsize, ysize), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # draw area used for transformation into transformed image\n",
    "        points = np.int32(dst.reshape((-1,1,2)))\n",
    "        dstareaimage = np.zeros_like(warpedimage)\n",
    "        cv2.polylines(dstareaimage, [points], True, (255, 0, 0), thickness = linewidth)\n",
    "        ret, addedwarped = addto_image(warpedimage, dstareaimage)\n",
    "        \n",
    "        # plot original and transformed images\n",
    "        figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        figure.tight_layout()\n",
    "        ax1.imshow(blended)\n",
    "        ax1.set_title('Image with area used for transformation', fontsize=30)\n",
    "        ax2.imshow(addedwarped)\n",
    "        ax2.set_title('Birdseye view test image', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "        \n",
    "        # get a list of test images\n",
    "        fileimages = glob.glob(os.path.join('.', testsubfolder, testimagemask))\n",
    "\n",
    "        # loop through all images\n",
    "        for idx, fileimage in enumerate(fileimages):\n",
    "            \n",
    "            # print name of used test image\n",
    "            print('Processing image:', fileimage)\n",
    "        \n",
    "            # read next test image\n",
    "            image = mpimg.imread(fileimage)\n",
    "            undistortedimage = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "            xsize = undistortedimage.shape[1]\n",
    "            ysize = undistortedimage.shape[0]\n",
    "            \n",
    "            # mark up corners in image\n",
    "            warpedimage = cv2.warpPerspective(undistortedimage, M, (xsize, ysize), flags=cv2.INTER_LINEAR)\n",
    "            figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "            figure.tight_layout()\n",
    "            ax1.imshow(undistortedimage)\n",
    "            ax1.set_title('Original test image', fontsize=30)\n",
    "            ax2.imshow(warpedimage)\n",
    "            ax2.set_title('Birdseye view test image', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "            plt.show()\n",
    "            \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    return ret, M, N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixels to real world\n",
    "\n",
    "The `pixels2realworld` function is based on the material from the Udacity SDC nanodegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels2realworld(mtx, dist, M, testsubfolder = 'test_images', testimage = 'straight_lines1.jpg', bdisplay = False):\n",
    "# ...\n",
    "# This function estimates the conversion from pixels to real world meters\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# mtx            : camera matrix\n",
    "# dist           : distortion coefficients\n",
    "# M              : perspective transformation to birdseye view\n",
    "# testsubfolder  : folder with test image\n",
    "# testimage      : test image name\n",
    "# bdisplay       : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# ret        : boolean for \"succesful execution\"\n",
    "# xm_per_pix : conversion from pixels to meters in horizontal/lateral direction\n",
    "# ym_per_pix : conversion from pixels to meters in vertical/longitudinal direction\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "        \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('pixels2realworld')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # constants\n",
    "    lanewidth = 3.7 # regulated minimum US lane width\n",
    "    dashedline = 3 # length of dashed line\n",
    "    dimensions_draw_offset = 100 # offset for drawing dimensions into image\n",
    "    linewidth = 10 # width of dimensions in image\n",
    "    \n",
    "    # initialize output\n",
    "    ret = True\n",
    "    \n",
    "    # read and undistort test image based on which conversion  will be determined\n",
    "    fileimage = os.path.join('.', testsubfolder, testimage)\n",
    "    image = mpimg.imread(fileimage)\n",
    "    undistortedimage = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    xsize = undistortedimage.shape[1]\n",
    "    ysize = undistortedimage.shape[0]\n",
    "    \n",
    "    # transform the image to birdseye view\n",
    "    warpedimage = cv2.warpPerspective(undistortedimage, M, (xsize, ysize), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # create binary image\n",
    "    binary = create_binary_image(warpedimage, bhls_s = True, hls_s_thresh = (50, 255), bdisplay = False)\n",
    "    \n",
    "    # Calculate conversions based on test image information\n",
    "    imagelanewidth = 450 # write code to detect the width of the lane in pixels in the test picture\n",
    "    xm_per_pix = lanewidth / imagelanewidth\n",
    "    imagedashedline = 70 # in the future write code to detect the length of a dashed line in pixels in the test image\n",
    "    ym_per_pix = dashedline / imagedashedline\n",
    "    \n",
    "    # draw and display test image with detected lane width and horizon\n",
    "    if bdisplay:\n",
    "        \n",
    "        # print name of used test image\n",
    "        print('Processing image:', fileimage)\n",
    "        \n",
    "        # create binary color picture with dimensions added\n",
    "        colorbinary = np.dstack((binary, binary, binary)) * 255\n",
    "        dimensions = np.zeros_like(colorbinary)\n",
    "        lanepointstartx = dimensions_draw_offset\n",
    "        lanepointendx = dimensions_draw_offset + imagelanewidth\n",
    "        lanepointstarty = ysize - dimensions_draw_offset\n",
    "        lanepointendy = ysize - dimensions_draw_offset\n",
    "        cv2.line(dimensions, (lanepointstartx, lanepointstarty), (lanepointendx, lanepointendy), (0, 255, 0) , thickness = linewidth)\n",
    "        linepointstartx = dimensions_draw_offset\n",
    "        linepointendx = dimensions_draw_offset\n",
    "        linepointstarty = ysize - dimensions_draw_offset\n",
    "        linepointendy = ysize - dimensions_draw_offset - imagedashedline\n",
    "        cv2.line(dimensions, (linepointstartx, linepointstarty), (linepointendx, linepointendy), (255, 0, 0) , thickness = linewidth)\n",
    "        ret, addedbinary = addto_image(colorbinary, dimensions)\n",
    "        \n",
    "        # plot original and processed image\n",
    "        warpedimage = cv2.warpPerspective(undistortedimage, M, (xsize, ysize), flags=cv2.INTER_LINEAR)\n",
    "        figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        figure.tight_layout()\n",
    "        ax1.imshow(undistortedimage)\n",
    "        ax1.set_title('Original test image', fontsize=30)\n",
    "        ax2.imshow(addedbinary)\n",
    "        ax2.set_title('Binary image to detect lane width and dashed line length', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "      \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    return ret, xm_per_pix, ym_per_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual camera setup\n",
    "\n",
    "The `camera setup` function combines all functions to determine the necessary image corrections and transformations due to the camera performance and installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_setup(bdisplay = False):\n",
    "# ...\n",
    "# This function calls the necessary functions to determine all parameters to correct for camera performance\n",
    "# and installation issues\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# bdisplay : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# ret        : boolean for \"succesful camera calibration\"\n",
    "# mtx        : camera matrix\n",
    "# dist       : distortion coefficients\n",
    "# rvecs      : rotation vectors\n",
    "# tvecs      : translation vectors\n",
    "# M          : transformation matrix from camera to birdseye view\n",
    "# N          : transformation matrix from birdseye view to camera\n",
    "# xm_per_pix : convertion from pixels to meters in horizontal/lateral direction\n",
    "# ym_per_pix : convertion from pixels to meters in vertical/longitudinal direction\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "        \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('camera_setup')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # determine distortion of camera\n",
    "    ret, mtx, dist, rvecs, tvecs = camera_calibration(bdisplay = bdisplay)\n",
    "    if not(ret):\n",
    "        raise Error('Couldn\\'t determine camera calibration')\n",
    "    \n",
    "    # determine transformation from camera to birdseye view\n",
    "    ret, M, N = camera2birdseyeview(mtx, dist, bdisplay = bdisplay)\n",
    "    if not(ret):\n",
    "        raise Error('Couldn\\'t determine transformation from camera to birdseye view')\n",
    "    \n",
    "    # determine transformation from pixels to real world\n",
    "    ret, xm_per_pix, ym_per_pix = pixels2realworld(mtx, dist, M, bdisplay = bdisplay)\n",
    "    if not(ret):\n",
    "        raise Error('Couldn\\'t determine convertion from pixels to real world')\n",
    "        \n",
    "    # display end of this function if necessary\n",
    "    if bdisplay:\n",
    "        \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    return mtx, dist, rvecs, tvecs, M, N, xm_per_pix, ym_per_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing images to detect the lane and lateral curvature\n",
    "\n",
    "The following section defines all functions that are necessary to process individual images to detect and mark up lanes. It also contains the functions that are necessary to determine the lateral lane curvature and the lateral offset from the center of the lane. There are also functions to decide whether or not prior knowledge can be used to simplify and improve lane detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate binary images to detect lane lines using different methods and parameters\n",
    "\n",
    "The `create_binary_image` function is based on the material from the Udacity SDC nanodegree and combines. It allows to combine different filters to generate a combined binary output channel. Several additional functions are defined to avoid repetition of the same code structure while allowing the flexibility for many different filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sobel(channel, xdir, ydir, ksize):\n",
    "# ...\n",
    "# This function calculates the sobel value of a channel\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# channel : color channel of an image\n",
    "# xdir    : magnitude of x direction [0, 1]\n",
    "# ydir    : magnitude of y direction [0, 1]\n",
    "# ksize   : kernel size for sobel operation [1, 3, 5, ...]\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# sobel : result of the sobel operation (same size as channel)\n",
    "   \n",
    "    # take the derivative\n",
    "    sobel = cv2.Sobel(channel, cv2.CV_64F, xdir, ydir, ksize = ksize)\n",
    "    \n",
    "    return sobel\n",
    "\n",
    "def absolute_channel(channel1, channel2 = None):\n",
    "# ...\n",
    "# This function calculates scaled absolute values for a channel using the magnitude if 2 channels are provided\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# channel1 : channel 1 of an image\n",
    "# channel2 : channel 2 of an image\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# scaled_channel : scaled absolute channel\n",
    "    \n",
    "    if channel2 is None:\n",
    "        # calculate absolute value\n",
    "        abs_channel = (channel1 ** 2) ** 0.5\n",
    "    else:\n",
    "        # calculate magnitude\n",
    "        abs_channel = ((channel1 ** 2) + (channel2 ** 2)) ** 0.5\n",
    "\n",
    "    # scale to [0, 255]\n",
    "    scaled_channel = 255 * abs_channel / np.max(abs_channel)\n",
    "    \n",
    "    return scaled_channel\n",
    "\n",
    "def channel_direction(channelx, channely):\n",
    "# ...\n",
    "# This function calculates the combined direction of an x and y channel\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# channelx : x derivative of color channel\n",
    "# channely : y derivative of color channel\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# direction : direction of combined channels\n",
    "   \n",
    "    # calculate direction\n",
    "    direction = np.arctan2(channely, channelx)\n",
    "    \n",
    "    return direction\n",
    "\n",
    "def apply_threshold(channel, thresh):\n",
    "# ...\n",
    "# This function applies a threshold to a channel and returns a binary channel\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# channel : channel of an image\n",
    "# thresh  : minimum and maximum threshold values\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# binary : binary channel\n",
    "   \n",
    "    # generate a binary channel based on provided thresholds\n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel >= thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    binary = np.uint8(binary)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def calculate_sobels(template, channel, bmag, bdir, bsobelx, bsobely, sobel_kernel, mag_thresh, dir_thresh, sobelx_thresh, sobely_thresh):\n",
    "# ...\n",
    "# This function applies a threshold to a channel and returns a binary channel\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# template      : template output depending on OR (zeros) or AND (ones) connection later\n",
    "# channel       : channel of an image\n",
    "# bmag          : boolean for \"process magnitude\"\n",
    "# bdir          : boolean for \"process direction\"\n",
    "# bsobelx       : boolean for \"process sobel in x\"\n",
    "# bsobely       : boolean for \"process sobel in y\"\n",
    "# sobel_kernel  : sobel kernel size\n",
    "# mag_thresh    : threshold for magnitude\n",
    "# dir_thresh    : threshold for direction\n",
    "# sobelx_thresh : threshold for sobel in x direction\n",
    "# sobely_thresh : threshold for sobel in y direction\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# mag_binary : binary channel for magnitude\n",
    "# dir_binary : binary channel for direction\n",
    "# sx_binary  : binary channel for sobel in x\n",
    "# sy_binary  : binary channel for sobel in y\n",
    "    \n",
    "    # initialize outputs\n",
    "    mag_binary = np.copy(template)\n",
    "    dir_binary = np.copy(template)\n",
    "    sx_binary = np.copy(template)\n",
    "    sy_binary = np.copy(template)\n",
    "    \n",
    "    if (bmag or bdir or bsobelx):\n",
    "        sobelx = do_sobel(channel, 1, 0, sobel_kernel)\n",
    "    if (bmag or bdir or bsobely):\n",
    "        sobely = do_sobel(channel, 0, 1, sobel_kernel)\n",
    "    if bmag:\n",
    "        mag_binary = apply_threshold(absolute_channel(sobelx, sobely), mag_thresh)\n",
    "    if bdir:\n",
    "        dir_binary = apply_threshold(channel_direction(sobelx, sobely), dir_thresh)\n",
    "    if bsobelx:\n",
    "        sx_binary = apply_threshold(absolute_channel(sobelx), sobelx_thresh)\n",
    "    if bsobely:\n",
    "        sy_binary = apply_threshold(absolute_channel(sobely), sobely_thresh)\n",
    "    \n",
    "    return mag_binary, dir_binary, sx_binary, sy_binary\n",
    "\n",
    "def cbi(binary_list, bOR = True, bdisplay = False):\n",
    "# ...\n",
    "# This function combined a list of binaries using AND or OR\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# binary_list : list of binary images\n",
    "# bOR         : boolean for \"use OR operator\"\n",
    "# bdisplay    : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# binary : combined binary image\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('cbi (combine binary image)')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    # initialize outputs\n",
    "    if bOR:\n",
    "        binary = np.zeros_like(binary_list[0])\n",
    "    else:\n",
    "        binary = np.ones_like(binary_list[0])\n",
    "    \n",
    "    # process all elements in binary list\n",
    "    elementshape = []\n",
    "    for idx, current_binary in enumerate(binary_list):\n",
    "        \n",
    "        # start combining with second binary\n",
    "        if (idx > 0):\n",
    "            \n",
    "            # make sure shapes match\n",
    "            if (current_binary.shape == elementshape):\n",
    "                \n",
    "                # combine current binary with output\n",
    "                if bOR:\n",
    "                    binary = (binary | current_binary)\n",
    "                else:\n",
    "                    binary = (binary & current_binary)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                raise Error('Binary shapes don\\'t match')\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            # use first binary as start\n",
    "            binary = current_binary\n",
    "            \n",
    "            # remember first binary shape\n",
    "            elementshape = current_binary.shape\n",
    "        \n",
    "    # display two images and result\n",
    "    if (bdisplay and (idx == 1)):\n",
    "        \n",
    "        # print name of used test image\n",
    "        print('Processing image size:', binary.shape)\n",
    "        \n",
    "        # print information\n",
    "        if bOR:\n",
    "            operator_string = 'OR'\n",
    "        else:\n",
    "            operator_string = 'AND'\n",
    "        print('Binary operator used for combining:', operator_string)\n",
    "        \n",
    "        # draw original image with lane and lane mask\n",
    "        figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 9))\n",
    "        figure.tight_layout()\n",
    "        ax1.imshow(binary_list[0], cmap='gray')\n",
    "        ax1.set_title('First binary image', fontsize=20)\n",
    "        ax2.imshow(binary_list[1], cmap='gray')\n",
    "        ax2.set_title('Second binary image', fontsize=20)\n",
    "        ax3.imshow(binary, cmap='gray')\n",
    "        ax3.set_title('Combined binary image', fontsize=20)\n",
    "        ax4.imshow(np.zeros_like(binary), cmap='gray')\n",
    "        ax4.set_title('<Empty>', fontsize=20)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "\n",
    "    # display end of function\n",
    "    if bdisplay:\n",
    "        \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    return binary\n",
    "\n",
    "def create_binary_image(image, bOR = False,\n",
    "                        bgray = False, gray_thresh = (180, 255),\n",
    "                        bgray_mag = False, bgray_dir = False, bgray_sx = False, bgray_sy = False,\n",
    "                        gray_sobel_kernel = 15, gray_mag_thresh=(100, 255), gray_dir_thresh = (0 + 0.5, (np.pi / 2) - 0.5),\n",
    "                        gray_sx_thresh = (70, 120), gray_sy_thresh = (100, 255), \n",
    "                        bhls_h = False, hls_h_thresh = (15, 50),\n",
    "                        bhls_h_mag = False, bhls_h_dir = False, bhls_h_sx = False, bhls_h_sy = False, \n",
    "                        hls_h_sobel_kernel = 15, hls_h_mag_thresh=(100, 255), hls_h_dir_thresh = (0 + 0.5, (np.pi / 2) - 0.5), \n",
    "                        hls_h_sx_thresh = (50, 150), hls_h_sy_thresh = (80, 200), \n",
    "                        bhls_l = False, hls_l_thresh = (140, 255), \n",
    "                        bhls_l_mag = False, bhls_l_dir = False, bhls_l_sx = False, bhls_l_sy = False, \n",
    "                        hls_l_sobel_kernel = 15, hls_l_mag_thresh=(30, 100), hls_l_dir_thresh = (0 + 0.5, (np.pi / 2) - 0.5), \n",
    "                        hls_l_sx_thresh = (30, 255), hls_l_sy_thresh = (50, 200), \n",
    "                        bhls_s = False, hls_s_thresh = (50, 255), \n",
    "                        bhls_s_mag = False, bhls_s_dir = False, bhls_s_sx = False, bhls_s_sy = False, \n",
    "                        hls_s_sobel_kernel = 15, hls_s_mag_thresh=(40, 255), hls_s_dir_thresh = (0 + 0.5, (np.pi / 2) - 0.5), \n",
    "                        hls_s_sx_thresh = (50, 255), hls_s_sy_thresh = (50, 255), \n",
    "                        bdisplay = False):\n",
    "# ...\n",
    "# This function creates a binary image applying a combination of algorithms to detect edges\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# <channel>              = placeholder for channel out of set {gray, hls_h, hls_l, hls_s}\n",
    "# image                  : RGB image\n",
    "# b<channel>             : boolean for \"process channel\"\n",
    "# <channel>_thresh       : threshold for color channel\n",
    "# b<channel>_mag         : boolean for \"process magnitude\"\n",
    "# b<channel>_dir         : boolean for \"process direction\"\n",
    "# b<channel>_sx          : boolean for \"process sobel in x\"\n",
    "# b<channel>_sy          : boolean for \"process sobel in y\"\n",
    "# <channel>_sobel_kernel : sobel kernel size\n",
    "# <channel>_mag_thresh   : threshold for magnitude\n",
    "# <channel>_dir_thresh   : threshold for direction\n",
    "# <channel>_sx_thresh    : threshold for sobel in x direction\n",
    "# <channel>_sy_thresh    : threshold for sobel in y direction\n",
    "# bdisplay               : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# combined_binary : combined binary channel\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('create_binary_image')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    # copy image to not change original\n",
    "    image = np.copy(image)\n",
    "    \n",
    "    # initialize intermediate outputs\n",
    "    output_template = image[:, : , 0]\n",
    "    if bOR:\n",
    "        template = np.zeros_like(output_template)\n",
    "    else:\n",
    "        template = np.ones_like(output_template)\n",
    "    gray_binary = np.copy(template)\n",
    "    gray_mag_binary = np.copy(template)\n",
    "    gray_dir_binary = np.copy(template)\n",
    "    gray_sx_binary = np.copy(template)\n",
    "    gray_sy_binary = np.copy(template)\n",
    "    hls_h_binary = np.copy(template)\n",
    "    hls_h_mag_binary = np.copy(template)\n",
    "    hls_h_dir_binary = np.copy(template)\n",
    "    hls_h_sx_binary = np.copy(template)\n",
    "    hls_h_sy_binary = np.copy(template)\n",
    "    hls_l_binary = np.copy(template)\n",
    "    hls_l_mag_binary = np.copy(template)\n",
    "    hls_l_dir_binary = np.copy(template)\n",
    "    hls_l_sx_binary = np.copy(template)\n",
    "    hls_l_sy_binary = np.copy(template)\n",
    "    hls_s_binary = np.copy(template)\n",
    "    hls_s_mag_binary = np.copy(template)\n",
    "    hls_s_dir_binary = np.copy(template)\n",
    "    hls_s_sx_binary = np.copy(template)\n",
    "    hls_s_sy_binary = np.copy(template)\n",
    "    \n",
    "    # convert image to all necessary color spaces\n",
    "    if (bgray or bgray_mag or bgray_dir or bgray_sx or bgray_sy):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if (bhls_h or bhls_h_mag or bhls_h_dir or bhls_h_sx or bhls_h_sy or \n",
    "          bhls_l or bhls_l_mag or bhls_l_dir or bhls_l_sx or bhls_l_sy or \n",
    "          bhls_s or bhls_s_mag or bhls_s_dir or bhls_s_sx or bhls_s_sy):\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        hls_h = hls[:,:,0]\n",
    "        hls_l = hls[:,:,1]\n",
    "        hls_s = hls[:,:,2]\n",
    "    \n",
    "    # calculate all necessary derivatives\n",
    "    if (bgray_mag or bgray_dir or bgray_sx or bgray_sy):\n",
    "        gray_mag_binary, gray_dir_binary, gray_sx_binary, gray_sy_binary = calculate_sobels(template, \n",
    "            gray, bgray_mag, bgray_dir, bgray_sx, bgray_sy, gray_sobel_kernel, \n",
    "            gray_mag_thresh, gray_dir_thresh, gray_sx_thresh, gray_sy_thresh)\n",
    "    if (bhls_h_mag or bhls_h_dir or bhls_h_sx or bhls_h_sy):\n",
    "        hls_h_mag_binary, hls_h_dir_binary, hls_h_sx_binary, hls_h_sy_binary = calculate_sobels(template, \n",
    "            hls_h, bhls_h_mag, bhls_h_dir, bhls_h_sx, bhls_h_sy, hls_h_sobel_kernel, \n",
    "            hls_h_mag_thresh, hls_h_dir_thresh, hls_h_sx_thresh, hls_h_sy_thresh)\n",
    "    if (bhls_l_mag or bhls_l_dir or bhls_l_sx or bhls_l_sy):\n",
    "        hls_l_mag_binary, hls_l_dir_binary, hls_l_sx_binary, hls_l_sy_binary = calculate_sobels(template, \n",
    "            hls_l, bhls_l_mag, bhls_l_dir, bhls_l_sx, bhls_l_sy, hls_l_sobel_kernel, \n",
    "            hls_l_mag_thresh, hls_l_dir_thresh, hls_l_sx_thresh, hls_l_sy_thresh)\n",
    "    if (bhls_s_mag or bhls_s_dir or bhls_s_sx or bhls_s_sy):\n",
    "        hls_s_mag_binary, hls_s_dir_binary, hls_s_sx_binary, hls_s_sy_binary = calculate_sobels(template, \n",
    "            hls_s, bhls_s_mag, bhls_s_dir, bhls_s_sx, bhls_s_sy, hls_s_sobel_kernel, \n",
    "            hls_s_mag_thresh, hls_s_dir_thresh, hls_s_sx_thresh, hls_s_sy_thresh)\n",
    "    \n",
    "    # apply necessary color channel thresholds\n",
    "    if bgray:\n",
    "        gray_binary = apply_threshold(gray, gray_thresh)\n",
    "    if bhls_h:\n",
    "        hls_h_binary = apply_threshold(hls_h, hls_h_thresh)\n",
    "    if bhls_l:\n",
    "        hls_l_binary = apply_threshold(hls_l, hls_l_thresh)\n",
    "    if bhls_s:\n",
    "        hls_s_binary = apply_threshold(hls_s, hls_s_thresh)\n",
    "        \n",
    "    # combine channels\n",
    "    if bOR:\n",
    "        combined_gray_binary = (gray_binary | gray_mag_binary | gray_dir_binary | gray_sx_binary | gray_sy_binary)\n",
    "        combined_hls_h_binary = (hls_h_binary | hls_h_mag_binary | hls_h_dir_binary | hls_h_sx_binary | hls_h_sy_binary)\n",
    "        combined_hls_l_binary = (hls_l_binary | hls_l_mag_binary | hls_l_dir_binary | hls_l_sx_binary | hls_l_sy_binary)\n",
    "        combined_hls_s_binary = (hls_s_binary | hls_s_mag_binary | hls_s_dir_binary | hls_s_sx_binary | hls_s_sy_binary)\n",
    "        combined_channel_binary = (gray_binary | hls_h_binary | hls_l_binary | hls_s_binary)\n",
    "        combined_mag_binary = (gray_mag_binary | hls_h_mag_binary | hls_l_mag_binary | hls_s_mag_binary)\n",
    "        combined_dir_binary = (gray_dir_binary | hls_h_dir_binary | hls_l_dir_binary | hls_s_dir_binary)\n",
    "        combined_sx_binary = (gray_sx_binary | hls_h_sx_binary | hls_l_sx_binary | hls_s_sx_binary)\n",
    "        combined_sy_binary = (gray_sy_binary | hls_h_sy_binary | hls_l_sy_binary | hls_s_sy_binary)\n",
    "        combined_s_binary = (combined_sx_binary | combined_sy_binary)\n",
    "        combined_binary = (combined_channel_binary | combined_mag_binary | combined_dir_binary | combined_s_binary)\n",
    "    else:\n",
    "        combined_gray_binary = (gray_binary & gray_mag_binary & gray_dir_binary & gray_sx_binary & gray_sy_binary)\n",
    "        combined_hls_h_binary = (hls_h_binary & hls_h_mag_binary & hls_h_dir_binary & hls_h_sx_binary & hls_h_sy_binary)\n",
    "        combined_hls_l_binary = (hls_l_binary & hls_l_mag_binary & hls_l_dir_binary & hls_l_sx_binary & hls_l_sy_binary)\n",
    "        combined_hls_s_binary = (hls_s_binary & hls_s_mag_binary & hls_s_dir_binary & hls_s_sx_binary & hls_s_sy_binary)\n",
    "        combined_channel_binary = (gray_binary & hls_h_binary & hls_l_binary & hls_s_binary)\n",
    "        combined_mag_binary = (gray_mag_binary & hls_h_mag_binary & hls_l_mag_binary & hls_s_mag_binary)\n",
    "        combined_dir_binary = (gray_dir_binary & hls_h_dir_binary & hls_l_dir_binary & hls_s_dir_binary)\n",
    "        combined_sx_binary = (gray_sx_binary & hls_h_sx_binary & hls_l_sx_binary & hls_s_sx_binary)\n",
    "        combined_sy_binary = (gray_sy_binary & hls_h_sy_binary & hls_l_sy_binary & hls_s_sy_binary)\n",
    "        combined_s_binary = (combined_sx_binary & combined_sy_binary)\n",
    "        combined_binary = (combined_channel_binary & combined_mag_binary & combined_dir_binary & combined_s_binary)\n",
    "    combined_color_binary = np.dstack((combined_binary, combined_binary, combined_binary)) * 255\n",
    "    combined_color_channel_binary = np.dstack((combined_channel_binary, combined_channel_binary, combined_channel_binary)) * 255\n",
    "    combined_color_magdirs_binary = np.dstack((combined_mag_binary, combined_dir_binary, combined_s_binary)) * 255\n",
    "\n",
    "    # draw and display image and combined binary image\n",
    "    if bdisplay:\n",
    "    \n",
    "        # print name of used test image\n",
    "        print('Processing image size:', image.shape)\n",
    "        \n",
    "        # compare original and binary image\n",
    "        figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 9))\n",
    "        figure.tight_layout()\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title('Original image', fontsize=20)\n",
    "        ax2.imshow(combined_color_binary)\n",
    "        ax2.set_title('Combined binary image', fontsize=20)\n",
    "        ax3.imshow(combined_color_channel_binary)\n",
    "        ax3.set_title('Combined channel binary image', fontsize=20)\n",
    "        ax4.imshow(combined_color_magdirs_binary)\n",
    "        ax4.set_title('Combined Mag Dir S binary image', fontsize=20)\n",
    "        plt.show()     \n",
    "\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify left and right lane lines with and without prior knowledge about their shape and positions\n",
    "\n",
    "The `sliding_window_detect` function can be called to detect lane, lane lines, lateral curvature and lateral offset from the center of the lane within a binary image with or without prior knowledge about the lane lines. It is based on the material from the Udacity SDC nanodegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_x_peak(binary, xmin, xmax, ymin, ymax, conv_width, bdisplay = False):\n",
    "# ...\n",
    "# This function detects peaks in x values of a binary image\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# binary     : binary image\n",
    "# xmin       : left corner of detection box relative to image\n",
    "# xmax       : right corner of detection box relative to image\n",
    "# ymin       : top corner of detection box relative to image\n",
    "# ymax       : bottom corner of detection box relative to image\n",
    "# conv_width : convolution window size\n",
    "# bdisplay   : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# xpeak : x position of peak in image\n",
    "# ypeak : y position of peak in image\n",
    "# ret   : boolean for \"successful operation\"\n",
    "    \n",
    "    # constants\n",
    "    min_conv_sum = (5 * 40) # line must be 5 pixels wide and 40 pixels high\n",
    "    peak_stand_out = 10 # percent of how much a line peak must stand out of the histogram to be valid\n",
    "    top_stand_out = 50 # percent of how much a close peak area must cover from the top points in the histogram\n",
    "    \n",
    "    # initialize output\n",
    "    xpeak = np.int(xmin + ((xmax - xmin) // 2))\n",
    "    ypeak = np.int(ymin + ((ymax - ymin) // 2))\n",
    "    ret = True\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('detect_x_peak')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # initial calculations\n",
    "    window = np.ones(conv_width) # convolution window\n",
    "    offset = np.int(conv_width // 2)\n",
    "    closeconvwidth = np.int(conv_width // 1)\n",
    "    \n",
    "    # generate histogram\n",
    "    histogram = np.sum(binary[ymin:ymax, xmin:xmax], axis = 0)\n",
    "    \n",
    "    # check whether histogram is not empty\n",
    "    if (len(histogram) > 0):\n",
    "        \n",
    "        # execute convolution\n",
    "        convolution = np.convolve(window, histogram)\n",
    "        \n",
    "        # detect peak\n",
    "        maximum = np.argmax(convolution)\n",
    "        potential_xpeak = np.int(maximum - offset + xmin)\n",
    "        \n",
    "        # check for valid data set\n",
    "        convolution_sum = np.sum(convolution)\n",
    "        b_valid_data_set = (convolution_sum >= min_conv_sum)\n",
    "        \n",
    "        # detect valid peak (small area around peak should have most points)\n",
    "        maxconv = max(convolution)\n",
    "        maxconvidx = maximum\n",
    "        mincloseconvidx = np.int(max(0, (maxconvidx - (closeconvwidth // 2))))\n",
    "        maxcloseconvidx = np.int(min((maxconvidx + (closeconvwidth // 2)), len(convolution)))\n",
    "        closeconv = convolution[mincloseconvidx:maxcloseconvidx]\n",
    "        convlimit = (maxconv * (1 - (peak_stand_out / 100)))\n",
    "        top_closeconv = closeconv[closeconv > convlimit]\n",
    "        top_closeconv_sum = np.sum(top_closeconv)\n",
    "        top_conv = convolution[convolution > convlimit]\n",
    "        top_conv_sum = np.sum(top_conv)\n",
    "        top_conv_ratio = (top_closeconv_sum / top_conv_sum)\n",
    "        b_valid_peak = (top_conv_ratio >= (1 - (top_stand_out / 100)))\n",
    "        \n",
    "        # detect whether peak is in search range\n",
    "        b_peak_in_range = ((xmin <= potential_xpeak) and (potential_xpeak <= xmax))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        b_valid_data_set = False\n",
    "        b_valid_peak = False\n",
    "        b_peak_in_range = False\n",
    "    \n",
    "    # success is valid data set and valid peak\n",
    "    if (b_valid_data_set and b_valid_peak and b_peak_in_range):\n",
    "        \n",
    "        # use peak position\n",
    "        xpeak = potential_xpeak\n",
    "        \n",
    "        # calculate y value of peak if there are valid values\n",
    "        ycontributing = np.arange(ymin, ymax) * binary[ymin:ymax, xpeak]\n",
    "        ycontributing = ycontributing[np.nonzero(ycontributing)]\n",
    "        if len(ycontributing):\n",
    "            ypeak = np.int(np.average(ycontributing))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # impossible to find a valid peak\n",
    "        ret = False\n",
    "        \n",
    "    # draw and display image and combined binary image\n",
    "    if bdisplay:\n",
    "        \n",
    "        # display information about findings\n",
    "        if ret:\n",
    "            print('Peak found at:', maximum)\n",
    "            print('x coordinate of peak is:', xmin, '<=', xpeak, '<=', xmax)\n",
    "            print('y coordinate of peak is:', ymin, '<=', ypeak, '<=', ymax)\n",
    "        else:\n",
    "            print('No peak found.')\n",
    "        print('Convolution sum is:', convolution_sum)\n",
    "        print('Minimum sum is:', min_conv_sum)\n",
    "        print('Top peak percentage coverage is:', top_conv_ratio)\n",
    "    \n",
    "        # draw original image and image with findings\n",
    "        figure, ax1 = plt.subplots(1, 1, figsize=(24, 9))\n",
    "        figure.tight_layout()\n",
    "        ax1.plot(histogram)\n",
    "        ax1.plot(convolution)\n",
    "        ax1.plot(convlimit * np.ones_like(convolution))\n",
    "        ax1.axvline(x=mincloseconvidx)\n",
    "        ax1.axvline(x=maxcloseconvidx)\n",
    "        ax1.set_title('Histogram and convolution', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    return ret, xpeak, ypeak\n",
    "\n",
    "def calculate_polynomial(line_centers, bdisplay):\n",
    "# ...\n",
    "# This function generates polynomials based on line centers\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# line_centers : list of points of a line\n",
    "# bdisplay     : boolean for \"display outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# line_poly : polynomial coefficients of calculated polynomial\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('calculate_polynomial')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # get x values\n",
    "    xvalues = []\n",
    "    for idx, point in enumerate(line_centers):\n",
    "        xvalues.append(point[0])\n",
    "    \n",
    "    # get y values\n",
    "    yvalues = []\n",
    "    for idx, point in enumerate(line_centers):\n",
    "        yvalues.append(point[1])\n",
    "    \n",
    "    # fit a second order polynomial\n",
    "    line_poly = np.polyfit(yvalues, xvalues, 2)\n",
    "    \n",
    "    # display information\n",
    "    if bdisplay:\n",
    "        \n",
    "        # display information about findings\n",
    "        print('Values in x:', xvalues)\n",
    "        print('Values in y:', yvalues)\n",
    "        print('Polynomial:', line_poly)\n",
    "\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    return line_poly\n",
    "\n",
    "def smooth_vector(new_vector, new_percentage, old_vector):\n",
    "# ...\n",
    "# This function smoothes a vector using a running average\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# new_vector     : new value\n",
    "# new_percentage : percentage of how much to use new value when smoothing\n",
    "# old_vector     : previous smoothed value\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# smoothed : smoothed value\n",
    "    \n",
    "    smoothed = ((new_percentage / 100) * new_vector) + ((1 - (new_percentage / 100)) * old_vector)\n",
    "    \n",
    "    return smoothed\n",
    "    \n",
    "def sliding_window_detect(binary, OldLeftLine, OldRightLine, OldAllLines, xm_per_pix, ym_per_pix, breusepoly = False, breusestart = False, bsmooth = False, bdisplay = False, bdisplaydetails = False, bdisplaydepth = False):\n",
    "# ...\n",
    "# This function detects left and right lines in a binary image\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# binary          : binary image\n",
    "# OldLeftLine     : previous left line information\n",
    "# OldRightLine    : previous right line information\n",
    "# OldAllLines     : all previous line information\n",
    "# xm_per_pix      : convertion from pixels to meters in horizontal/lateral direction\n",
    "# ym_per_pix      : convertion from pixels to meters in vertical/longitudinal direction\n",
    "# breusepoly      : boolean for \"reuse last polynomial\"\n",
    "# breusestart     : boolean for \"reuse last starting position\"\n",
    "# bsmooth         : boolean for \"smooth polynomials\"\n",
    "# bdisplay        : boolean for \"display outputs\"\n",
    "# bdisplaydetails : boolean for \"display detailed outputs\"\n",
    "# bdisplaydepth   : boolean for \"display all detailed outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# ret                      : boolean for \"successful operation\"\n",
    "# line_centers             : list of left and right line centers\n",
    "# valid_line_centers_left  : list of valid left line centers\n",
    "# valid_line_centers_right : list of valid right line centers\n",
    "# NewLeftLine              : left line information\n",
    "# NewRightLine             : right line information\n",
    "# lane_mask                : lane mask image used to overlay lane and lane lines in image\n",
    "\n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('sliding_window_detect')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # constants\n",
    "    xstartminpercent = 10 # percentage of left corner of box to find lines relative to image\n",
    "    xstartmaxpercent = 90 # percentage of right corner of box to find lines relative to image\n",
    "    ystartminpercent = 70 # percentage of top corner of box to find lines relative to image\n",
    "    ystartmaxpercent = 100 # percentage of bottom corner of box to find lines relative to image\n",
    "    windowlevels = 9 # number of sliding windows\n",
    "    margin = 80 # 100 # set the width of the windows +/- margin\n",
    "    conv_width = 50 # window width for convolution\n",
    "    boxeswidth = 5 # width of boxes\n",
    "    centerwidth = 10 # width of center lines\n",
    "    line_marker_width = 50 # width of line markers in output\n",
    "    with_knowledge_minimum_line_centers_percent = 85  # percentage of minimum line centers for successful operation (nearly all to be able to reuse last fit)\n",
    "    without_knowledge_minimum_line_centers = (3 + 1) # minimum line centers for successful operation (3 for polynomial plus 1 to not overfit)\n",
    "    new_percentage = 25 # percentage of how much new polynomial influences used polynomial\n",
    "    \n",
    "    # initial calculations\n",
    "    xsize = binary.shape[1]\n",
    "    ysize = binary.shape[0]\n",
    "    window_height = np.int(ysize // windowlevels)\n",
    "    offset = np.int(conv_width / 2)\n",
    "    initialcenterwidth = 2 * centerwidth\n",
    "    with_knowledge_minimum_line_centers = np.int(windowlevels * (with_knowledge_minimum_line_centers_percent / 100))\n",
    "    \n",
    "    # initialize output\n",
    "    ret = False\n",
    "    line_centers =[]\n",
    "    valid_line_centers_left =[]\n",
    "    valid_line_centers_right =[]\n",
    "    all_valid_line_centers = []\n",
    "    NewLeftLine = Line() # copy.deepcopy(OldLeftLine)\n",
    "    NewRightLine = Line() # copy.deepcopy(OldRightLine)\n",
    "    NewAllLines = Line() # copy.deepcopy(OldAllLines)\n",
    "    \n",
    "    # calculate search box\n",
    "    xmin = np.int(xsize * xstartminpercent / 100)\n",
    "    xmax = np.int(xsize * xstartmaxpercent / 100)\n",
    "    ymin = np.int(ysize * ystartminpercent / 100)\n",
    "    ymax = np.int(ysize * ystartmaxpercent / 100)\n",
    "    xminleft = xmin\n",
    "    xmaxleft = xmin + np.int((xmax - xmin) // 2)\n",
    "    xminright = xmaxleft\n",
    "    xmaxright = xmax\n",
    "    \n",
    "    # initialize success variable \n",
    "    bstartingpositionsfound = False\n",
    "    \n",
    "    # reuse start positions\n",
    "    if breusestart:\n",
    "        \n",
    "        # retrieve start peaks\n",
    "        xpeak_left, ypeak_left = OldLeftLine.startpeak\n",
    "        xpeak_right, ypeak_right = OldRightLine.startpeak\n",
    "        \n",
    "        # save start peaks\n",
    "        NewLeftLine.startpeak = (xpeak_left, ypeak_left)\n",
    "        NewRightLine.startpeak = (xpeak_right, ypeak_right)\n",
    "        \n",
    "        # return success\n",
    "        bstartingpositionsfound = True\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        # find starting lines\n",
    "        ret_left, xpeak_left, ypeak_left = detect_x_peak(binary, xminleft, xmaxleft, ymin, ymax, conv_width, bdisplaydepth)\n",
    "        ret_right, xpeak_right, ypeak_right = detect_x_peak(binary, xminright, xmaxright, ymin, ymax, conv_width, bdisplaydepth)\n",
    "        \n",
    "        # check for success\n",
    "        if (ret_left and ret_right):\n",
    "            \n",
    "            # save start peaks\n",
    "            NewLeftLine.startpeak = (xpeak_left, ypeak_left)\n",
    "            NewRightLine.startpeak = (xpeak_right, ypeak_right)\n",
    "            \n",
    "            # return success\n",
    "            bstartingpositionsfound = True\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # return no success\n",
    "            bstartingpositionsfound = False\n",
    "    \n",
    "    # check whether starting position could be found\n",
    "    if bstartingpositionsfound:\n",
    "            \n",
    "        # calculate lateral lane marker distance\n",
    "        #lineoffset = (xpeak_right - xpeak_left)\n",
    "        #offcenter = ((xpeak_left - 0) - (xsize - xpeak_right))\n",
    "    \n",
    "        # add boxes to display image if necessary\n",
    "        if bdisplay:\n",
    "                \n",
    "            # create color image from binary image\n",
    "            binary_draw = np.dstack((binary, binary, binary)) * 255\n",
    "                \n",
    "            # draw initial lines and boxes\n",
    "            cv2.line(binary_draw, (xpeak_left, ypeak_left), (xpeak_left, ymax), (0, 255, 0) , thickness = initialcenterwidth)\n",
    "            cv2.line(binary_draw, (xpeak_right, ypeak_right), (xpeak_right, ymax), (0, 255, 0) , thickness = initialcenterwidth)\n",
    "            cv2.rectangle(binary_draw, (xminleft, ymin), (xmaxleft, ymax), (255, 255, 0), thickness = boxeswidth)\n",
    "            cv2.rectangle(binary_draw, (xminright, ymin), (xmaxright, ymax), (0, 255, 255), thickness = boxeswidth)\n",
    "            \n",
    "        # for each layer look for max pixel locations\n",
    "        for idx, level in enumerate(range(windowlevels)):\n",
    "                \n",
    "            # save previous peaks\n",
    "            old_xpeak_left = xpeak_left\n",
    "            old_ypeak_left = ypeak_left\n",
    "            old_xpeak_right = xpeak_right\n",
    "            old_ypeak_right = ypeak_right\n",
    "        \n",
    "            # calculate search box\n",
    "            ymin = np.int(ysize - ((level + 1) * window_height))\n",
    "            ymax = np.int(ysize - (level * window_height))\n",
    "            line_y = (ymin + ((ymax - ymin) // 2))\n",
    "                \n",
    "            # left search box locations based on previous findings\n",
    "            if (breusepoly and OldLeftLine.detected):\n",
    "                \n",
    "                # get previous polynomials\n",
    "                left_line_poly = OldLeftLine.current_fit\n",
    "                    \n",
    "                # calculate search box\n",
    "                poly_xpeak_left = (left_line_poly[0] * line_y**2) + (left_line_poly[1] * line_y) + left_line_poly[2]\n",
    "                xminleft = np.int(max(poly_xpeak_left - margin, 0))\n",
    "                xmaxleft = np.int(min(poly_xpeak_left + margin, xsize))\n",
    "                    \n",
    "            else:\n",
    "                    \n",
    "                # calculate search box\n",
    "                xminleft = np.int(max(old_xpeak_left - margin, 0))\n",
    "                xmaxleft = np.int(min(old_xpeak_left + margin, xsize))\n",
    "                \n",
    "            # right search box locations based on previous findings\n",
    "            if (breusepoly and OldRightLine.detected):\n",
    "                \n",
    "                # get previous polynomials\n",
    "                right_line_poly = OldRightLine.current_fit\n",
    "                    \n",
    "                # calculate search box\n",
    "                poly_xpeak_right = (right_line_poly[0] * line_y**2) + (right_line_poly[1] * line_y) + right_line_poly[2]\n",
    "                xminright = np.int(max(poly_xpeak_right - margin, 0))\n",
    "                xmaxright = np.int(min(poly_xpeak_right + margin, xsize))\n",
    "                    \n",
    "            else:\n",
    "                    \n",
    "                # calculate search box\n",
    "                xminright = np.int(max(old_xpeak_right - margin, 0))\n",
    "                xmaxright = np.int(min(old_xpeak_right + margin, xsize))\n",
    "                \n",
    "            # find next lines\n",
    "            ret_left, xpeak_left, ypeak_left = detect_x_peak(binary, xminleft, xmaxleft, ymin, ymax, conv_width, bdisplaydepth)\n",
    "            ret_right, xpeak_right, ypeak_right = detect_x_peak(binary, xminright, xmaxright, ymin, ymax, conv_width, bdisplaydepth)\n",
    "            \n",
    "            # calculate lane width and off center position in first iteration \n",
    "            if (idx == 0):\n",
    "                \n",
    "                # calculate lateral lane marker distance\n",
    "                potentiallineoffset = (xpeak_right - xpeak_left)\n",
    "                potentialoffcenter = ((xsize - xpeak_right) - (xpeak_left - 0))\n",
    "            \n",
    "            # check for any unsuccessful operation and save valid line centers\n",
    "            if ret_left:\n",
    "                valid_line_centers_left.append((xpeak_left, ypeak_left))\n",
    "                all_valid_line_centers.append(((xpeak_left + np.int(potentiallineoffset // 2)), ypeak_left))\n",
    "            else:\n",
    "                xpeak_left = old_xpeak_left # use old x peak\n",
    "                ypeak_left = old_ypeak_left # use old y peak\n",
    "            if ret_right:\n",
    "                valid_line_centers_right.append((xpeak_right, ypeak_right))\n",
    "                all_valid_line_centers.append(((xpeak_right - np.int(potentiallineoffset // 2)), ypeak_right))\n",
    "            else:\n",
    "                xpeak_right = old_xpeak_right # use old x peak\n",
    "                ypeak_right = old_ypeak_right # use old y peak\n",
    "                \n",
    "            # save line centers\n",
    "            line_centers.append(((xpeak_left, ypeak_left), (xpeak_right, ypeak_right)))\n",
    "                \n",
    "            # add boxes to display image if necessary\n",
    "            if bdisplay:\n",
    "                if ret_left:\n",
    "                    cv2.line(binary_draw, (xpeak_left, ypeak_left), (xpeak_left, ymax), (255, 0, 0) , thickness = centerwidth)\n",
    "                if ret_right:\n",
    "                    cv2.line(binary_draw, (xpeak_right, ypeak_right), (xpeak_right, ymax), (0, 0, 255) , thickness = centerwidth)\n",
    "                cv2.rectangle(binary_draw, (xminleft, ymin), (xmaxleft, ymax), (255, 0, 0), thickness = boxeswidth)\n",
    "                cv2.rectangle(binary_draw, (xminright, ymin), (xmaxright, ymax), (0, 0, 255), thickness = boxeswidth)\n",
    "            \n",
    "        # determine criteria\n",
    "        if (breusestart or breusepoly):\n",
    "            minimum_line_centers = with_knowledge_minimum_line_centers\n",
    "        else:\n",
    "            minimum_line_centers = without_knowledge_minimum_line_centers\n",
    "            \n",
    "        # determine success\n",
    "        num_valid_line_centers_left = len(valid_line_centers_left)\n",
    "        ret_left = (num_valid_line_centers_left >= minimum_line_centers)\n",
    "        num_valid_line_centers_right = len(valid_line_centers_right)\n",
    "        ret_right = (num_valid_line_centers_right >= minimum_line_centers)\n",
    "        ret = (ret_left and ret_right)            \n",
    "            \n",
    "        # calculate outputs\n",
    "        NewLeftLine.detected = ret_left\n",
    "        NewRightLine.detected = ret_right\n",
    "        NewAllLines.detected = (ret_left and ret_right)\n",
    "    \n",
    "    else:\n",
    "            \n",
    "        # unsuccessful execution\n",
    "        ret = False\n",
    "            \n",
    "        # calculate outputs\n",
    "        NewLeftLine.detected = ret\n",
    "        NewRightLine.detected = ret\n",
    "        NewAllLines.detected = ret\n",
    "    \n",
    "        # raise Error('Couldn\\'t find starting lane lines')\n",
    "    \n",
    "    # define empty binary image\n",
    "    binary_empty = np.zeros_like(binary)\n",
    "    \n",
    "    # successfully found line markers\n",
    "    if ret:\n",
    "        \n",
    "        # successful calculations\n",
    "        lineoffset = potentiallineoffset\n",
    "        offcenter = potentialoffcenter\n",
    "        NewAllLines.line_base_pos = offcenter\n",
    "        \n",
    "        # calculate new polynomials for left and right lane line\n",
    "        left_line_poly_new = calculate_polynomial(valid_line_centers_left, (bdisplaydetails or bdisplaydepth))\n",
    "        right_line_poly_new = calculate_polynomial(valid_line_centers_right, (bdisplaydetails or bdisplaydepth))\n",
    "        all_line_poly_new = calculate_polynomial(all_valid_line_centers, (bdisplaydetails or bdisplaydepth))\n",
    "        \n",
    "        # save current fit\n",
    "        NewLeftLine.current_fit = left_line_poly_new\n",
    "        NewRightLine.current_fit = right_line_poly_new\n",
    "        NewAllLines.current_fit = all_line_poly_new\n",
    "        \n",
    "        # smooth polynomials\n",
    "        if bsmooth:\n",
    "            if OldLeftLine.detected:\n",
    "                left_line_poly = smooth_vector(left_line_poly_new, new_percentage, OldLeftLine.best_fit)\n",
    "            else:\n",
    "                left_line_poly = left_line_poly_new\n",
    "            if OldRightLine.detected:\n",
    "                right_line_poly = smooth_vector(right_line_poly_new, new_percentage, OldRightLine.best_fit)\n",
    "            else:\n",
    "                right_line_poly = right_line_poly_new\n",
    "            if (OldLeftLine.detected and OldRightLine.detected):\n",
    "                all_line_poly = smooth_vector(all_line_poly_new, new_percentage, OldAllLines.best_fit)\n",
    "            else:\n",
    "                all_line_poly = all_line_poly_new\n",
    "        else:\n",
    "            left_line_poly = left_line_poly_new\n",
    "            right_line_poly = right_line_poly_new\n",
    "            all_line_poly = all_line_poly_new\n",
    "\n",
    "        # create lane mask\n",
    "        line_y = np.arange(0, ysize)\n",
    "        left_line_x = (left_line_poly[0] * line_y**2) + (left_line_poly[1] * line_y) + left_line_poly[2]\n",
    "        right_line_x = (right_line_poly[0] * line_y**2) + (right_line_poly[1] * line_y) + right_line_poly[2]\n",
    "        center_line_x = (all_line_poly[0] * line_y**2) + (all_line_poly[1] * line_y) + all_line_poly[2]\n",
    "        binary_lane = np.copy(binary_empty)\n",
    "        for idx, y in enumerate(range(ysize)):\n",
    "            left = np.int(left_line_x[idx])\n",
    "            right = np.int(right_line_x[idx])\n",
    "            binary_lane[idx, left:right] = 1\n",
    "        lane_mask = np.dstack((binary_empty, binary_lane, binary_empty)) * 255\n",
    "        \n",
    "        # create left and right lane markers\n",
    "        point_list_left = np.dstack((left_line_x, line_y))\n",
    "        points_left = np.int32(point_list_left.reshape((-1,1,2)))\n",
    "        cv2.polylines(lane_mask, [points_left], False, (255, 0, 0), thickness = line_marker_width)\n",
    "        point_list_right = np.dstack((right_line_x, line_y))\n",
    "        points_right = np.int32(point_list_right.reshape((-1,1,2)))\n",
    "        cv2.polylines(lane_mask, [points_right], False, (0, 0, 255), thickness = line_marker_width)\n",
    "        point_list_center = np.dstack((center_line_x, line_y))\n",
    "        points_center = np.int32(point_list_center.reshape((-1,1,2)))\n",
    "        cv2.polylines(lane_mask, [points_center], False, (255, 255, 255), thickness = line_marker_width)\n",
    "        \n",
    "        # calculate lateral curvature\n",
    "        left_curverad = ((1 + (2 * left_line_poly[0] * line_y * ym_per_pix + left_line_poly[1])**2)**1.5) / np.absolute(2 * left_line_poly[0])\n",
    "        right_curverad = ((1 + (2 * right_line_poly[0] * line_y * ym_per_pix + right_line_poly[1])**2)**1.5) / np.absolute(2 * right_line_poly[0])\n",
    "        all_curverad = ((1 + (2 * all_line_poly[0] * line_y * ym_per_pix + all_line_poly[1])**2)**1.5) / np.absolute(2 * all_line_poly[0])\n",
    "        \n",
    "        # save lateral curvature values\n",
    "        NewLeftLine.radius_of_curvature = np.average(left_curverad)\n",
    "        NewRightLine.radius_of_curvature = np.average(right_curverad)\n",
    "        NewAllLines.radius_of_curvature = np.average(all_curverad)\n",
    "        \n",
    "        # calculate outputs\n",
    "        NewLeftLine.best_fit = left_line_poly\n",
    "        NewRightLine.best_fit = right_line_poly\n",
    "        NewAllLines.best_fit = all_line_poly\n",
    "    \n",
    "        # draw and display image and combined binary image\n",
    "        if bdisplay:\n",
    "            \n",
    "            # print name of used test image\n",
    "            print('Processing image size:', binary_draw.shape)\n",
    "            \n",
    "            # print statistics\n",
    "            print('Line centers found on left side:', num_valid_line_centers_left)\n",
    "            print('Line centers found on right side:', num_valid_line_centers_right)\n",
    "            print('Lateral curvature in km:', (np.int(np.average(all_curverad)) / 1000))\n",
    "            print('Lateral lane width in m:', (np.int(lineoffset * xm_per_pix * 100) / 100))\n",
    "            print('Lateral offset in m:', (np.int(offcenter * xm_per_pix * 100) / 100))\n",
    "    \n",
    "            # draw original image and image with findings\n",
    "            figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "            figure.tight_layout()\n",
    "            ax1.imshow(binary, cmap='gray')\n",
    "            ax1.set_title('Original binary image', fontsize=30)\n",
    "            ax2.imshow(binary_draw)\n",
    "            ax2.set_title('Binary image with findings', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "            plt.show()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # return empty lane mask\n",
    "        lane_mask = np.dstack((binary_empty, binary_empty, binary_empty)) * 255\n",
    "        \n",
    "        # ensure consistent output\n",
    "        NewAllLines.line_base_pos = None\n",
    "        NewLeftLine.current_fit = None\n",
    "        NewRightLine.current_fit = None\n",
    "        NewAllLines.current_fit = None        \n",
    "        NewLeftLine.radius_of_curvature = None\n",
    "        NewRightLine.radius_of_curvature = None\n",
    "        NewAllLines.radius_of_curvature = None\n",
    "        NewLeftLine.best_fit = None\n",
    "        NewRightLine.best_fit = None\n",
    "        NewAllLines.best_fit = None\n",
    "        \n",
    "        # display information\n",
    "        if bdisplay:\n",
    "        \n",
    "            # print information\n",
    "            print('No line centers found.')\n",
    "        \n",
    "    # display end of function\n",
    "    if bdisplay:\n",
    "            \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # unused line parameters - just for documentation\n",
    "    # x values of the last n fits of the line\n",
    "    #self.recent_xfitted = [] \n",
    "    #average x values of the fitted line over the last n iterations\n",
    "    #self.bestx = None     \n",
    "    #difference in fit coefficients between last and new fits\n",
    "    #self.diffs = np.array([0,0,0], dtype='float') \n",
    "    #x values for detected line pixels\n",
    "    #self.allx = None  \n",
    "    #y values for detected line pixels\n",
    "    #self.ally = None\n",
    "    \n",
    "    return ret, line_centers, valid_line_centers_left, valid_line_centers_right, NewLeftLine, NewRightLine, NewAllLines, lane_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage left and right lane line detection quality and determine what to use\n",
    "\n",
    "The `process_video_frame` function marks up lane and lane lines as well as estimates the lateral curvature of the lane. It also manages which algorithm to choose to detect the lane, e.g. how much to trust the newly detected lane information versus using the information from the previous frame. It is based on the material from the Udacity SDC nanodegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_frame(frame, mtx, dist, M, xm_per_pix, ym_per_pix, OldLeftLine, OldRightLine, OldAllLines, OldLane, bsmooth = False, bdisplay = False, bdisplaydetails = False, bdisplaydepth = False):\n",
    "# ...\n",
    "# This function processes a video stream by marking up the lane and lane lines as well as\n",
    "# estimating the lateral curvature of the lane\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# frame           : image frame of video stream\n",
    "# mtx             : camera matrix\n",
    "# dist            : distortion coefficients\n",
    "# M               : transformation matrix from camera to birdseye view\n",
    "# xm_per_pix      : convertion from pixels to meters in horizontal/lateral direction\n",
    "# ym_per_pix      : convertion from pixels to meters in vertical/longitudinal direction\n",
    "# OldLeftLine     : previous left line information\n",
    "# OldRightLine    : previous right line information\n",
    "# OldAllLines     : all previous line information\n",
    "# OldLane         : previous lane information\n",
    "# bsmooth         : boolean for \"smooth polynomials\"\n",
    "# bdisplay        : boolean for \"display outputs\"\n",
    "# bdisplaydetails : boolean for \"display detailed outputs\"\n",
    "# bdisplaydepth   : boolean for \"display all detailed outputs\"\n",
    "# ...\n",
    "# Outputs\n",
    "# ...\n",
    "# outputframe  : output video frame\n",
    "# breusepoly   : boolean for \"success reusing polynomial from previous frame\"\n",
    "# breusestart  : boolean for \"success reusing starting position from previous frame\"\n",
    "# OldLeftLine  : saved left line information\n",
    "# OldRightLine : saved right line information\n",
    "# OldLane      : saved lane information\n",
    "    \n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('process_video_frame')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "        # draw original image\n",
    "        figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        figure.tight_layout()\n",
    "        ax1.imshow(frame)\n",
    "        ax1.set_title('Original image', fontsize=30)\n",
    "        ax2.imshow(np.zeros_like(frame))\n",
    "        ax2.set_title('<Empty>', fontsize=30)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()        \n",
    "    \n",
    "    # constants\n",
    "    displayfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    textposition = (30, 50)\n",
    "    verticaltextoffset = 50\n",
    "    fontsize = 1\n",
    "    fontcolor = (255, 255, 0)\n",
    "    fontthickness = 3\n",
    "    \n",
    "    # initialize outputs\n",
    "    breusepoly = False\n",
    "    breusestart = False\n",
    "    \n",
    "    # correct image distortion\n",
    "    undistortedimage = cv2.undistort(frame, mtx, dist, None, mtx)\n",
    "    xsize = undistortedimage.shape[1]\n",
    "    ysize = undistortedimage.shape[0]\n",
    "    \n",
    "    # transform the image to birdseye view\n",
    "    warpedimage = cv2.warpPerspective(undistortedimage, M, (xsize, ysize), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # detect white lines\n",
    "    #binary_white = create_binary_image(warpedimage, bOR = False, \n",
    "    #                    bgray = True, gray_thresh = (100, 255),\n",
    "    #                    bhls_s_sx = True, hls_s_sobel_kernel = 15, hls_s_sx_thresh = (10, 255),  \n",
    "    #                    bdisplay = bdisplaydetails)\n",
    "    binary_white = create_binary_image(warpedimage, bOR = False, \n",
    "                        bhls_l = True, hls_l_thresh = (180, 255),\n",
    "                        bhls_l_sx = True, hls_l_sobel_kernel = 31, hls_l_sx_thresh = (20, 255),  \n",
    "                        bdisplay = bdisplaydetails)\n",
    "    \n",
    "    # detect yellow lines\n",
    "    #binary_yellow = create_binary_image(warpedimage, bOR = False, \n",
    "    #                    bhls_h = True, hls_h_thresh = (20, 70),\n",
    "    #                    bhls_l_sx = True, hls_l_sobel_kernel = 15, hls_l_sx_thresh = (5, 255), \n",
    "    #                    bdisplay = bdisplaydetails)\n",
    "    binary_yellow = create_binary_image(warpedimage, bOR = False, \n",
    "                        bhls_h = True, hls_h_thresh = (15, 70),\n",
    "                        bhls_s_sx = True, hls_s_sobel_kernel = 31, hls_s_sx_thresh = (15, 255), \n",
    "                        bdisplay = bdisplaydetails)\n",
    "    \n",
    "    # combine binary for white and yello lines\n",
    "    binary = cbi((binary_white, binary_yellow), bOR = True, bdisplay = bdisplay)\n",
    "    \n",
    "    # previous parameters - just for reference\n",
    "    #binary = create_binary_image(warpedimage, bOR = False,\n",
    "    #                    bhls_l_mag = True, hls_l_sobel_kernel = 15, hls_l_mag_thresh=(30, 100), \n",
    "    #                    bhls_s = True, hls_s_thresh = (10, 255)\n",
    "    #                    bdisplay = bdisplaydetails)\n",
    "    #binary = create_binary_image(warpedimage, bOR = True, \n",
    "    #                    bgray_sx = True, gray_sobel_kernel = 15, gray_sx_thresh = (50, 120), \n",
    "    #                    bhls_s = True, hls_s_thresh = (150, 255), \n",
    "    #                    bdisplay = bdisplaydetails)\n",
    "    #binary = create_binary_image(warpedimage, bOR = True, \n",
    "    #                    bgray_sx = True, gray_sobel_kernel = 15, gray_sx_thresh = (50, 120), \n",
    "    #                    bhls_s = True, hls_s_thresh = (200, 255), \n",
    "    #                    bdisplay = bdisplaydetails)\n",
    "    \n",
    "    # starting without having had success yet\n",
    "    ret = False\n",
    "\n",
    "    # find lane lines using previous findings\n",
    "    if (OldLeftLine.detected and OldRightLine.detected):\n",
    "        \n",
    "        # display progress\n",
    "        if bdisplay:\n",
    "            print('Finding lanes lines with prior knowledge...')\n",
    "    \n",
    "        ret, line_centers, valid_line_centers_left, valid_line_centers_right, NewLeftLine, NewRightLine, NewAllLines, lane_mask = sliding_window_detect(\n",
    "            binary, OldLeftLine, OldRightLine, OldAllLines, xm_per_pix, ym_per_pix, bsmooth = bsmooth, \n",
    "            breusepoly = True, breusestart = True, bdisplay = bdisplay, bdisplaydetails = bdisplaydetails, bdisplaydepth = bdisplaydepth)\n",
    "        \n",
    "        # check whether success counter needs to be increased\n",
    "        if ret:\n",
    "            breusepoly = True\n",
    "        \n",
    "        # display progress\n",
    "        if bdisplay:\n",
    "            if ret:\n",
    "                print('Success!')\n",
    "            else:\n",
    "                print('No success!')\n",
    "    \n",
    "    # find lane lines using previous start position\n",
    "    if (not ret and (OldLeftLine.detected and OldRightLine.detected)):\n",
    "        \n",
    "        # display progress\n",
    "        if bdisplay:\n",
    "            print('Finding lanes lines with prior starting position...')\n",
    "        \n",
    "        ret, line_centers, valid_line_centers_left, valid_line_centers_right, NewLeftLine, NewRightLine, NewAllLines, lane_mask = sliding_window_detect(\n",
    "            binary, OldLeftLine, OldRightLine, OldAllLines, xm_per_pix, ym_per_pix, bsmooth = bsmooth, \n",
    "            breusepoly = False, breusestart = True, bdisplay = bdisplay, bdisplaydetails = bdisplaydetails, bdisplaydepth = bdisplaydepth)\n",
    "        \n",
    "        # check whether success counter needs to be increased\n",
    "        if ret:\n",
    "            breusestart = True\n",
    "        \n",
    "        # display progress\n",
    "        if bdisplay:\n",
    "            if ret:\n",
    "                print('Success!')\n",
    "            else:\n",
    "                print('No success!')\n",
    "        \n",
    "    # find lane lines using full sliding window algorithm\n",
    "    if not ret:\n",
    "        \n",
    "        # display progress\n",
    "        if bdisplay:\n",
    "            print('Finding lanes lines without prior knowledge...')\n",
    "        \n",
    "        ret, line_centers, valid_line_centers_left, valid_line_centers_right, NewLeftLine, NewRightLine, NewAllLines, lane_mask = sliding_window_detect(\n",
    "            binary, OldLeftLine, OldRightLine, OldAllLines, xm_per_pix, ym_per_pix, bsmooth = bsmooth, \n",
    "            breusepoly = False, breusestart = False, bdisplay = bdisplay, bdisplaydetails = bdisplaydetails, bdisplaydepth = bdisplaydepth)\n",
    "        \n",
    "        # display progress\n",
    "        if bdisplay:\n",
    "            if ret:\n",
    "                print('Success!')\n",
    "            else:\n",
    "                print('No success!')\n",
    "        \n",
    "    # save successfully detected new lines and lane mask\n",
    "    if ret:\n",
    "        OldLeftLine = NewLeftLine\n",
    "        OldRightLine = NewRightLine\n",
    "        OldAllLines = NewAllLines\n",
    "        OldLane.lane_mask = lane_mask\n",
    "    elif not (len(OldLane.lane_mask) == 0):\n",
    "        lane_mask = OldLane.lane_mask\n",
    "    \n",
    "    if not (len(lane_mask) == 0):\n",
    "        \n",
    "        # draw lane lines in output frame\n",
    "        lane_mask_original = cv2.warpPerspective(lane_mask, N, (xsize, ysize), flags=cv2.INTER_LINEAR)\n",
    "        outputframe = blendinto_image(undistortedimage, lane_mask_original, 0.5)\n",
    "        \n",
    "        # draw successfully detected lateral curvature and off center position\n",
    "        all_curverad = NewAllLines.radius_of_curvature\n",
    "        old_all_curverad = OldAllLines.radius_of_curvature\n",
    "        if ((all_curverad == None) and (not (old_all_curverad == None))):\n",
    "            all_curverad = old_all_curverad\n",
    "        if not (all_curverad == None):\n",
    "            text = 'Lateral curvature in km: ' + str(np.int(all_curverad) / 1000)\n",
    "            cv2.putText(outputframe, text, (textposition[0], textposition[1]), displayfont, fontsize, fontcolor, fontthickness, cv2.LINE_AA)\n",
    "        offcenter = NewAllLines.line_base_pos\n",
    "        old_offcenter = OldAllLines.line_base_pos\n",
    "        if ((offcenter == None) and (not (old_offcenter == None))):\n",
    "            offcenter = old_offcenter\n",
    "        if not (offcenter == None):\n",
    "            text = 'Lateral offset in m: ' + str((np.int(offcenter * xm_per_pix * 100) / 100))\n",
    "            cv2.putText(outputframe, text, (textposition[0], (textposition[1] + verticaltextoffset)), displayfont, fontsize, fontcolor, fontthickness, cv2.LINE_AA)\n",
    "            \n",
    "        # draw and display image and combined binary image if success\n",
    "        if (bdisplay and ret):\n",
    "            \n",
    "            # print name of used test image\n",
    "            print('Processing image size:', frame.shape)\n",
    "            \n",
    "            # draw original image with lane and lane mask\n",
    "            figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "            figure.tight_layout()\n",
    "            ax1.imshow(outputframe)\n",
    "            ax1.set_title('Original image with lane', fontsize=30)\n",
    "            ax2.imshow(lane_mask)\n",
    "            ax2.set_title('Lane mask', fontsize=30)\n",
    "            plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "            plt.show()\n",
    "\n",
    "    # display end of function\n",
    "    if bdisplay:\n",
    "        \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "        \n",
    "    return ret, outputframe, breusepoly, breusestart, OldLeftLine, OldRightLine, OldAllLines, OldLane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual video processing\n",
    "\n",
    "The `process_video` function loads a video stream and processes every individual frame in it. The processing includes marking up lane and lane lines as well as estimating the lateral curvature of the lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(videofilename, outputfilename, mtx, dist, M, xm_per_pix, ym_per_pix, bdisplay = False, displayfrequency = 100, bdisplaydetails = False, bdisplaydepth = False):\n",
    "# ...\n",
    "# This function loads a video file, processes it and then writes it to the output file\n",
    "# ...\n",
    "# Inputs\n",
    "# ...\n",
    "# videofilename    : name of the input video file\n",
    "# outputfilename   : name of the output video file\n",
    "# mtx              : camera matrix\n",
    "# dist             : distortion coefficients\n",
    "# M                : transformation matrix from camera to birdseye view\n",
    "# xm_per_pix       : convertion from pixels to meters in horizontal/lateral direction\n",
    "# ym_per_pix       : convertion from pixels to meters in vertical/longitudinal direction\n",
    "# bdisplay         : boolean for \"display outputs\"\n",
    "# displayfrequency : boolean for \"display outputs\"\n",
    "# bdisplaydetails  : boolean for \"display detailed outputs\"\n",
    "# bdisplaydepth    : boolean for \"display all detailed outputs\"\n",
    "\n",
    "    # display beginning of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "        print('process_video')\n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "    \n",
    "    # load the original video stream\n",
    "    #videoclip = VideoFileClip(videofilename).subclip(0.3, 0.8)\n",
    "    videoclip = VideoFileClip(videofilename)\n",
    "    \n",
    "    # get information about video stream\n",
    "    numframes = np.int(videoclip.duration * videoclip.fps)\n",
    "    \n",
    "    # display information\n",
    "    if bdisplay:\n",
    "    \n",
    "        # print information about video file\n",
    "        print('Processing video file:', videofilename)\n",
    "        print('Video resolution:', videoclip.size)\n",
    "        print('Number of frames:', numframes)\n",
    "    \n",
    "    # initialize succes counters\n",
    "    num_success_frames = 0\n",
    "    num_reuse_poly_success = 0\n",
    "    num_reuse_start_success = 0\n",
    "    \n",
    "    # initialize output video\n",
    "    outputvideo = []\n",
    "    \n",
    "    # generate objects to store previous line findings\n",
    "    OldLeftLine = Line()\n",
    "    OldRightLine = Line()\n",
    "    OldAllLines = Line()\n",
    "    OldLane = Lane()\n",
    "    \n",
    "    # process all frames of the video stream\n",
    "    for idx, frame in enumerate(videoclip.iter_frames()):\n",
    "        \n",
    "        # determine whether to display more in depth information\n",
    "        bdisplayframe = (((idx % displayfrequency) == 0) or (idx == numframes))\n",
    "        \n",
    "        # display progress\n",
    "        if (bdisplay and bdisplayframe):\n",
    "            \n",
    "            print('Processing frame:', idx)\n",
    "        \n",
    "        # process the video frame: mark up the lane and line lines as well as determine the lateral lane curvature\n",
    "        ret, outputframe, breusepoly, breusestart, OldLeftLine, OldRightLine, OldAllLines, OldLane = process_video_frame(\n",
    "            frame, mtx, dist, M, xm_per_pix, ym_per_pix, OldLeftLine, OldRightLine, OldAllLines, OldLane, \n",
    "            bsmooth = True, bdisplay = (bdisplay and bdisplayframe), bdisplaydetails = (bdisplaydetails and bdisplayframe), bdisplaydepth = (bdisplaydepth and bdisplayframe))\n",
    "        \n",
    "        # check for successes\n",
    "        if ret:\n",
    "            num_success_frames = num_success_frames + 1\n",
    "        if breusepoly:\n",
    "            num_reuse_poly_success = num_reuse_poly_success + 1\n",
    "        if breusestart:\n",
    "            num_reuse_start_success = num_reuse_start_success + 1\n",
    "        \n",
    "        # add output to output video\n",
    "        outputvideo.append(outputframe)\n",
    "    \n",
    "    # close video reader\n",
    "    videoclip.reader.close()\n",
    "    \n",
    "    # write the marked up video stream\n",
    "    outputclip = ImageSequenceClip(outputvideo, fps = videoclip.fps)\n",
    "    outputclip.write_videofile(outputfilename, fps = videoclip.fps)\n",
    "    \n",
    "    # display end of this function if necessary\n",
    "    if bdisplay:\n",
    "    \n",
    "        # print statistics about video processing\n",
    "        print('Successfully processed frames:', num_success_frames)\n",
    "        print('Processed by reusing polynomial:', num_reuse_poly_success)\n",
    "        print('Processed by reusing starting position:', num_reuse_start_success)\n",
    "    \n",
    "        print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline execution\n",
    "\n",
    "The following code contains the pipeline to execute everything that is necessary to mark up the lane in an input video and determine the curvature of the lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### main pipeline ###\n",
    "\n",
    "# set up the camera\n",
    "mtx, dist, rvecs, tvecs, M, N, xm_per_pix, ym_per_pix = camera_setup(bdisplay = False)\n",
    "\n",
    "# process the video\n",
    "videofilename1 = './project_video.mp4'\n",
    "outputfilename1 = './output_images/output.mp4'\n",
    "process_video(videofilename1, outputfilename1, mtx, dist, M, xm_per_pix, ym_per_pix, bdisplay = True, displayfrequency = 200, bdisplaydetails = True, bdisplaydepth = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(outputfilename1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### challenge pipeline ###\n",
    "\n",
    "# set up the camera\n",
    "mtx, dist, rvecs, tvecs, M, N, xm_per_pix, ym_per_pix = camera_setup(bdisplay = False)\n",
    "\n",
    "# process the video\n",
    "videofilename2 = './challenge_video.mp4'\n",
    "outputfilename2 = './output_images/output_challenge.mp4'\n",
    "process_video(videofilename2, outputfilename2, mtx, dist, M, xm_per_pix, ym_per_pix, bdisplay = True, displayfrequency = 100, bdisplaydetails = False, bdisplaydepth = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(outputfilename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### harder challenge pipeline ###\n",
    "\n",
    "# set up the camera\n",
    "mtx, dist, rvecs, tvecs, M, N, xm_per_pix, ym_per_pix = camera_setup(bdisplay = False)\n",
    "\n",
    "# process the video\n",
    "videofilename3 = './harder_challenge_video.mp4'\n",
    "outputfilename3 = './output_images/output_harder_challenge.mp4'\n",
    "process_video(videofilename3, outputfilename3, mtx, dist, M, xm_per_pix, ym_per_pix, bdisplay = True, displayfrequency = 200, bdisplaydetails = False, bdisplaydepth = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(outputfilename3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline test\n",
    "\n",
    "The following code contains the pipeline to test all functions with the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### test pipeline ###\n",
    "\n",
    "# set up the camera\n",
    "mtx, dist, rvecs, tvecs, M, N, xm_per_pix, ym_per_pix = camera_setup(bdisplay = True)\n",
    "\n",
    "# get a list of test images\n",
    "testsubfolder = 'test_images'\n",
    "calimagemask = '*.jpg'\n",
    "fileimages = glob.glob(os.path.join('.', testsubfolder, calimagemask))\n",
    "\n",
    "OldLeftLine = Line()\n",
    "OldRightLine = Line()\n",
    "OldAllLines = Line()\n",
    "OldLane = Lane()\n",
    "\n",
    "for fileimage in fileimages:\n",
    "    image = mpimg.imread(fileimage)\n",
    "    \n",
    "    ret, outputframe, breusepoly, breusestart, OldLeftLine, OldRightLine, OldAllLines, OldLane = process_video_frame(\n",
    "        image, mtx, dist, M, xm_per_pix, ym_per_pix, OldLeftLine, OldRightLine, OldAllLines, OldLane, \n",
    "        bsmooth = False, bdisplay = True, bdisplaydetails = True, bdisplaydepth = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.5.5"
=======
   "version": "3.6.5"
>>>>>>> 2caad97cc21c9303756acb38405f194ac3d05bec
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
